{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注意(attention)！开始做前必读项！\n",
    "\n",
    "- 所有的代码一定要在这个文件里面编写，不要自己创建一个新的文件\n",
    "- 对于提供的数据集，不要改存储地方，也不要修改文件名和内容\n",
    "- 确保到时候git pull之后我们可以直接运行这个 starter_code文件\n",
    "- 不要重新定义函数（如果我们已经定义好的），按照里面的思路来编写。当然，除了我们定义的部分，如有需要可以自行定义函数或者模块\n",
    "- 写完之后，重新看一下哪一部分比较慢，然后试图去优化。一个好的习惯是每写一部分就思考这部分代码的时间复杂度和空间复杂度，AI工程是的日常习惯！\n",
    "- 第一次作业很重要，一定要完成！ 相信会有很多的收获！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T05:43:17.765142Z",
     "start_time": "2020-02-24T05:43:16.709800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'做做事': 1,\n",
       " '做做饭': 1,\n",
       " '做做': 1,\n",
       " '做作': 1,\n",
       " '做主': 1,\n",
       " '做针线': 1,\n",
       " '做张做智': 1,\n",
       " '做张做致': 1,\n",
       " '做张做势': 1,\n",
       " '做贼心虚': 1,\n",
       " '做月子': 1,\n",
       " '做一天和尚撞一天钟': 1,\n",
       " '做一日和尚撞一天钟': 1,\n",
       " '做秀': 1,\n",
       " '做小伏低': 1,\n",
       " '做戏': 1,\n",
       " '做文章': 1,\n",
       " '做为': 1,\n",
       " '做头': 1,\n",
       " '做通': 1,\n",
       " '做私商勾当': 1,\n",
       " '做寿': 1,\n",
       " '做手脚': 1,\n",
       " '做事': 1,\n",
       " '做市商': 1,\n",
       " '做生意': 1,\n",
       " '做生日': 1,\n",
       " '做神做鬼': 1,\n",
       " '做人做世': 1,\n",
       " '做人': 1,\n",
       " '做起': 1,\n",
       " '做派': 1,\n",
       " '做梦': 1,\n",
       " '做媒': 1,\n",
       " '做礼拜': 1,\n",
       " '做客': 1,\n",
       " '做假账': 1,\n",
       " '做家教': 1,\n",
       " '做活儿': 1,\n",
       " '做活': 1,\n",
       " '做好做恶': 1,\n",
       " '做好做歹': 1,\n",
       " '做好': 1,\n",
       " '做鬼做神': 1,\n",
       " '做鬼': 1,\n",
       " '做官者': 1,\n",
       " '做官当老爷': 1,\n",
       " '做官': 1,\n",
       " '做功': 1,\n",
       " '做工精细': 1,\n",
       " '做工': 1,\n",
       " '做刚做柔': 1,\n",
       " '做饭': 1,\n",
       " '做法': 1,\n",
       " '做东道': 1,\n",
       " '做东': 1,\n",
       " '做到': 1,\n",
       " '做大做强': 1,\n",
       " '做出': 1,\n",
       " '做成': 1,\n",
       " '做操': 1,\n",
       " '做菜': 1,\n",
       " '做不了': 1,\n",
       " '做伴': 1,\n",
       " '做爱': 1,\n",
       " '做': 1,\n",
       " '座座': 1,\n",
       " '座子': 1,\n",
       " '座钟': 1,\n",
       " '座右铭': 1,\n",
       " '座椅': 1,\n",
       " '座像': 1,\n",
       " '座向': 1,\n",
       " '座席': 1,\n",
       " '座无虚席': 1,\n",
       " '座位图': 1,\n",
       " '座位数': 1,\n",
       " '座位号': 1,\n",
       " '座位费': 1,\n",
       " '座位表': 1,\n",
       " '座位': 1,\n",
       " '座套': 1,\n",
       " '座谈会': 1,\n",
       " '座谈': 1,\n",
       " '座上客': 1,\n",
       " '座上宾': 1,\n",
       " '座山峰': 1,\n",
       " '座山雕': 1,\n",
       " '座圈': 1,\n",
       " '座区': 1,\n",
       " '座骑': 1,\n",
       " '座票': 1,\n",
       " '座盘': 1,\n",
       " '座落在': 1,\n",
       " '座落': 1,\n",
       " '座楼': 1,\n",
       " '座架': 1,\n",
       " '座驾': 1,\n",
       " '座机': 1,\n",
       " '座环': 1,\n",
       " '座号': 1,\n",
       " '座豪华': 1,\n",
       " '座垫': 1,\n",
       " '座次': 1,\n",
       " '座充': 1,\n",
       " '座车': 1,\n",
       " '座厕': 1,\n",
       " '座舱': 1,\n",
       " '座标': 1,\n",
       " '座便器': 1,\n",
       " '座便': 1,\n",
       " '座': 1,\n",
       " '唑': 1,\n",
       " '祚庆': 1,\n",
       " '祚': 1,\n",
       " '胙': 1,\n",
       " '怍': 1,\n",
       " '阼': 1,\n",
       " '坐坐': 1,\n",
       " '坐姿': 1,\n",
       " '坐庄': 1,\n",
       " '坐支': 1,\n",
       " '坐镇': 1,\n",
       " '坐诊': 1,\n",
       " '坐在': 1,\n",
       " '坐运筹策': 1,\n",
       " '坐月子': 1,\n",
       " '坐浴': 1,\n",
       " '坐于涂炭': 1,\n",
       " '坐拥书城': 1,\n",
       " '坐拥百城': 1,\n",
       " '坐椅': 1,\n",
       " '坐以待旦': 1,\n",
       " '坐以待毙': 1,\n",
       " '坐药': 1,\n",
       " '坐言起行': 1,\n",
       " '坐薪悬胆': 1,\n",
       " '坐薪尝胆': 1,\n",
       " '坐像': 1,\n",
       " '坐享其功': 1,\n",
       " '坐享其成': 1,\n",
       " '坐下': 1,\n",
       " '坐席': 1,\n",
       " '坐无虚席': 1,\n",
       " '坐卧针毡': 1,\n",
       " '坐卧不宁': 1,\n",
       " '坐卧不离': 1,\n",
       " '坐卧不安': 1,\n",
       " '坐位表': 1,\n",
       " '坐位': 1,\n",
       " '坐堂': 1,\n",
       " '坐探': 1,\n",
       " '坐台': 1,\n",
       " '坐树无言': 1,\n",
       " '坐树不言': 1,\n",
       " '坐守': 1,\n",
       " '坐收渔利': 1,\n",
       " '坐收': 1,\n",
       " '坐视成败': 1,\n",
       " '坐视不救': 1,\n",
       " '坐视不管': 1,\n",
       " '坐视': 1,\n",
       " '坐式': 1,\n",
       " '坐食山空': 1,\n",
       " '坐失事机': 1,\n",
       " '坐失良机': 1,\n",
       " '坐失机宜': 1,\n",
       " '坐失': 1,\n",
       " '坐上琴心': 1,\n",
       " '坐商': 1,\n",
       " '坐山观虎斗': 1,\n",
       " '坐山雕': 1,\n",
       " '坐骑': 1,\n",
       " '坐盆': 1,\n",
       " '坐喷气式': 1,\n",
       " '坐南朝北': 1,\n",
       " '坐落': 1,\n",
       " '坐立不安': 1,\n",
       " '坐力': 1,\n",
       " '坐冷板凳': 1,\n",
       " '坐牢': 1,\n",
       " '坐困愁城': 1,\n",
       " '坐客': 1,\n",
       " '坐具': 1,\n",
       " '坐井观天': 1,\n",
       " '坐禁闭': 1,\n",
       " '坐江山': 1,\n",
       " '坐监': 1,\n",
       " '坐怀不乱': 1,\n",
       " '坐化': 1,\n",
       " '坐果': 1,\n",
       " '坐观成败': 1,\n",
       " '坐骨神经': 1,\n",
       " '坐骨': 1,\n",
       " '坐功': 1,\n",
       " '坐而论道': 1,\n",
       " '坐而待旦': 1,\n",
       " '坐而待弊': 1,\n",
       " '坐而待毙': 1,\n",
       " '坐墩': 1,\n",
       " '坐蔸': 1,\n",
       " '坐定': 1,\n",
       " '坐垫': 1,\n",
       " '坐地自划': 1,\n",
       " '坐地分脏': 1,\n",
       " '坐地分赃': 1,\n",
       " '坐地': 1,\n",
       " '坐凳': 1,\n",
       " '坐等': 1,\n",
       " '坐待': 1,\n",
       " '坐大': 1,\n",
       " '坐次': 1,\n",
       " '坐床': 1,\n",
       " '坐船': 1,\n",
       " '坐筹帷幄': 1,\n",
       " '坐吃山空': 1,\n",
       " '坐吃山崩': 1,\n",
       " '坐车': 1,\n",
       " '坐禅': 1,\n",
       " '坐厕': 1,\n",
       " '坐舱': 1,\n",
       " '坐不重席': 1,\n",
       " '坐不窥堂': 1,\n",
       " '坐不改姓': 1,\n",
       " '坐不垂堂': 1,\n",
       " '坐不安席': 1,\n",
       " '坐标轴': 1,\n",
       " '坐标系': 1,\n",
       " '坐标': 1,\n",
       " '坐便器': 1,\n",
       " '坐便': 1,\n",
       " '坐北朝南': 1,\n",
       " '坐班制': 1,\n",
       " '坐班': 1,\n",
       " '坐': 1,\n",
       " '作作有芒': 1,\n",
       " '作作': 1,\n",
       " '作祖': 1,\n",
       " '作子': 1,\n",
       " '作主': 1,\n",
       " '作忠': 1,\n",
       " '作证': 1,\n",
       " '作者投稿': 1,\n",
       " '作者群': 1,\n",
       " '作者': 1,\n",
       " '作哲': 1,\n",
       " '作战室': 1,\n",
       " '作战区': 1,\n",
       " '作战科': 1,\n",
       " '作战服': 1,\n",
       " '作战处': 1,\n",
       " '作战部': 1,\n",
       " '作战': 1,\n",
       " '作贼心虚': 1,\n",
       " '作育人材': 1,\n",
       " '作用力': 1,\n",
       " '作用点': 1,\n",
       " '作用': 1,\n",
       " '作勇': 1,\n",
       " '作翊': 1,\n",
       " '作役': 1,\n",
       " '作义': 1,\n",
       " '作揖': 1,\n",
       " '作业组': 1,\n",
       " '作业证': 1,\n",
       " '作业者': 1,\n",
       " '作业员': 1,\n",
       " '作业线': 1,\n",
       " '作业题': 1,\n",
       " '作业区': 1,\n",
       " '作业面': 1,\n",
       " '作业率': 1,\n",
       " '作业流程': 1,\n",
       " '作业量': 1,\n",
       " '作业机': 1,\n",
       " '作业费': 1,\n",
       " '作业队': 1,\n",
       " '作业点': 1,\n",
       " '作业车': 1,\n",
       " '作业本': 1,\n",
       " '作业': 1,\n",
       " '作言造语': 1,\n",
       " '作训服': 1,\n",
       " '作训': 1,\n",
       " '作秀': 1,\n",
       " '作兴': 1,\n",
       " '作协': 1,\n",
       " '作孝': 1,\n",
       " '作小服低': 1,\n",
       " '作响': 1,\n",
       " '作宪': 1,\n",
       " '作息时间': 1,\n",
       " '作息': 1,\n",
       " '作物': 1,\n",
       " '作务衣': 1,\n",
       " '作武': 1,\n",
       " '作文指导': 1,\n",
       " '作文网': 1,\n",
       " '作文题': 1,\n",
       " '作文课': 1,\n",
       " '作文辅导': 1,\n",
       " '作文簿': 1,\n",
       " '作文本': 1,\n",
       " '作文': 1,\n",
       " '作伪者': 1,\n",
       " '作伪': 1,\n",
       " '作为': 1,\n",
       " '作威作福': 1,\n",
       " '作威': 1,\n",
       " '作图': 1,\n",
       " '作田': 1,\n",
       " '作态': 1,\n",
       " '作祟': 1,\n",
       " '作手脚': 1,\n",
       " '作适': 1,\n",
       " '作势': 1,\n",
       " '作士': 1,\n",
       " '作生': 1,\n",
       " '作舍道旁': 1,\n",
       " '作舍道边': 1,\n",
       " '作善降祥': 1,\n",
       " '作善': 1,\n",
       " '作如是观': 1,\n",
       " '作人': 1,\n",
       " '作曲者': 1,\n",
       " '作曲系': 1,\n",
       " '作曲家': 1,\n",
       " '作曲法': 1,\n",
       " '作曲编曲': 1,\n",
       " '作曲': 1,\n",
       " '作乔': 1,\n",
       " '作品展示': 1,\n",
       " '作品展览': 1,\n",
       " '作品展': 1,\n",
       " '作品阅读': 1,\n",
       " '作品选': 1,\n",
       " '作品欣赏': 1,\n",
       " '作品赏析': 1,\n",
       " '作品目录': 1,\n",
       " '作品列表': 1,\n",
       " '作品简介': 1,\n",
       " '作品集': 1,\n",
       " '作品': 1,\n",
       " '作陪': 1,\n",
       " '作派': 1,\n",
       " '作呕': 1,\n",
       " '作弄': 1,\n",
       " '作孽': 1,\n",
       " '作鸟兽散': 1,\n",
       " '作难': 1,\n",
       " '作牧': 1,\n",
       " '作民': 1,\n",
       " '作美': 1,\n",
       " '作梅': 1,\n",
       " '作洛': 1,\n",
       " '作乱': 1,\n",
       " '作料': 1,\n",
       " '作乐': 1,\n",
       " '作浪兴风': 1,\n",
       " '作朗': 1,\n",
       " '作客思想': 1,\n",
       " '作客': 1,\n",
       " '作金石声': 1,\n",
       " '作娇': 1,\n",
       " '作践': 1,\n",
       " '作贱': 1,\n",
       " '作件': 1,\n",
       " '作茧自缚': 1,\n",
       " '作奸犯科': 1,\n",
       " '作嫁衣裳': 1,\n",
       " '作价': 1,\n",
       " '作假者': 1,\n",
       " '作假': 1,\n",
       " '作家作品': 1,\n",
       " '作家资料': 1,\n",
       " '作家在线': 1,\n",
       " '作家杂志': 1,\n",
       " '作家协会': 1,\n",
       " '作家网': 1,\n",
       " '作家群': 1,\n",
       " '作家风景': 1,\n",
       " '作家档案': 1,\n",
       " '作家出版社': 1,\n",
       " '作家': 1,\n",
       " '作画': 1,\n",
       " '作好作歹': 1,\n",
       " '作好': 1,\n",
       " '作翰': 1,\n",
       " '作鬼': 1,\n",
       " '作怪': 1,\n",
       " '作谷': 1,\n",
       " '作古正经': 1,\n",
       " '作古': 1,\n",
       " '作工': 1,\n",
       " '作梗': 1,\n",
       " '作福作威': 1,\n",
       " '作孚': 1,\n",
       " '作夫': 1,\n",
       " '作风建设': 1,\n",
       " '作风': 1,\n",
       " '作废': 1,\n",
       " '作坊式': 1,\n",
       " '作坊': 1,\n",
       " '作范': 1,\n",
       " '作法自弊': 1,\n",
       " '作法自毙': 1,\n",
       " '作法': 1,\n",
       " '作伐': 1,\n",
       " '作恶者': 1,\n",
       " '作恶多端': 1,\n",
       " '作恶': 1,\n",
       " '作厄': 1,\n",
       " '作对': 1,\n",
       " '作东': 1,\n",
       " '作登乡': 1,\n",
       " '作到': 1,\n",
       " '作代会': 1,\n",
       " '作大': 1,\n",
       " '作答': 1,\n",
       " '作词家': 1,\n",
       " '作词': 1,\n",
       " '作辍无常': 1,\n",
       " '作出': 1,\n",
       " '作成': 1,\n",
       " '作宾': 1,\n",
       " '作别': 1,\n",
       " '作壁上观': 1,\n",
       " '作弊器': 1,\n",
       " '作弊': 1,\n",
       " '作保': 1,\n",
       " '作伴儿': 1,\n",
       " '作伴': 1,\n",
       " '作罢': 1,\n",
       " '作案者': 1,\n",
       " '作案人': 1,\n",
       " '作案': 1,\n",
       " '作': 1,\n",
       " '佐佐木元': 1,\n",
       " '佐佐木': 1,\n",
       " '佐佐': 1,\n",
       " '佐助': 1,\n",
       " '佐竹': 1,\n",
       " '佐州': 1,\n",
       " '佐治亚州': 1,\n",
       " '佐治亚大学': 1,\n",
       " '佐治亚': 1,\n",
       " '佐治': 1,\n",
       " '佐织': 1,\n",
       " '佐之才': 1,\n",
       " '佐证': 1,\n",
       " '佐钊': 1,\n",
       " '佐佑': 1,\n",
       " '佐饔得尝': 1,\n",
       " '佐雍得尝': 1,\n",
       " '佐雍得': 1,\n",
       " '佐弋': 1,\n",
       " '佐伊': 1,\n",
       " '佐野': 1,\n",
       " '佐享': 1,\n",
       " '佐相': 1,\n",
       " '佐维奇': 1,\n",
       " '佐托夫': 1,\n",
       " '佐藤嘉恭': 1,\n",
       " '佐藤': 1,\n",
       " '佐特': 1,\n",
       " '佐塔': 1,\n",
       " '佐书': 1,\n",
       " '佐使': 1,\n",
       " '佐山': 1,\n",
       " '佐人': 1,\n",
       " '佐钦': 1,\n",
       " '佐派': 1,\n",
       " '佐纳': 1,\n",
       " '佐幕': 1,\n",
       " '佐谋': 1,\n",
       " '佐默': 1,\n",
       " '佐命': 1,\n",
       " '佐米曲坦': 1,\n",
       " '佐美': 1,\n",
       " '佐洛埃格塞格': 1,\n",
       " '佐洛': 1,\n",
       " '佐罗': 1,\n",
       " '佐卢': 1,\n",
       " '佐林': 1,\n",
       " '佐料': 1,\n",
       " '佐理': 1,\n",
       " '佐拉': 1,\n",
       " '佐克': 1,\n",
       " '佐卡': 1,\n",
       " '佐酒': 1,\n",
       " '佐剂': 1,\n",
       " '佐欢': 1,\n",
       " '佐贺县': 1,\n",
       " '佐贺': 1,\n",
       " '佐哈尔': 1,\n",
       " '佐国': 1,\n",
       " '佐攻者': 1,\n",
       " '佐格': 1,\n",
       " '佐夫斯基': 1,\n",
       " '佐夫': 1,\n",
       " '佐法尔': 1,\n",
       " '佐尔坦': 1,\n",
       " '佐尔格': 1,\n",
       " '佐尔': 1,\n",
       " '佐恩': 1,\n",
       " '佐渡岛': 1,\n",
       " '佐斗': 1,\n",
       " '佐登': 1,\n",
       " '佐村镇': 1,\n",
       " '佐川': 1,\n",
       " '佐车': 1,\n",
       " '佐餐': 1,\n",
       " '佐伯': 1,\n",
       " '佐埃': 1,\n",
       " '佐': 1,\n",
       " '左左右右': 1,\n",
       " '左宗棠': 1,\n",
       " '左枝右梧': 1,\n",
       " '左支右吾': 1,\n",
       " '左支右调': 1,\n",
       " '左支右绌': 1,\n",
       " '左证': 1,\n",
       " '左镇乡': 1,\n",
       " '左镇': 1,\n",
       " '左云县': 1,\n",
       " '左云': 1,\n",
       " '左右翼': 1,\n",
       " '左右眼': 1,\n",
       " '左右为难': 1,\n",
       " '左右腿': 1,\n",
       " '左右图史': 1,\n",
       " '左右手': 1,\n",
       " '左右脑': 1,\n",
       " '左右两难': 1,\n",
       " '左右开弓': 1,\n",
       " '左右江': 1,\n",
       " '左右逢源': 1,\n",
       " '左右逢原': 1,\n",
       " '左右方': 1,\n",
       " '左右侧': 1,\n",
       " '左右采获': 1,\n",
       " '左右岸': 1,\n",
       " '左右': 1,\n",
       " '左拥右抱': 1,\n",
       " '左萦右拂': 1,\n",
       " '左营': 1,\n",
       " '左翼文化运动': 1,\n",
       " '左翼': 1,\n",
       " '左宜右有': 1,\n",
       " '左宜右宜': 1,\n",
       " '左眼': 1,\n",
       " '左延安': 1,\n",
       " '左旋肉碱': 1,\n",
       " '左旋炔诺孕酮': 1,\n",
       " '左旋咪唑涂布剂': 1,\n",
       " '左旋': 1,\n",
       " '左舷': 1,\n",
       " '左贤王': 1,\n",
       " '左贤': 1,\n",
       " '左下角': 1,\n",
       " '左下方': 1,\n",
       " '左下': 1,\n",
       " '左膝': 1,\n",
       " '左溪': 1,\n",
       " '左文襄公': 1,\n",
       " '左文': 1,\n",
       " '左腿': 1,\n",
       " '左徒': 1,\n",
       " '左图右书': 1,\n",
       " '左图右史': 1,\n",
       " '左图': 1,\n",
       " '左铁镛': 1,\n",
       " '左天觉': 1,\n",
       " '左提右挈': 1,\n",
       " '左藤': 1,\n",
       " '左思右想': 1,\n",
       " '左思': 1,\n",
       " '左司马': 1,\n",
       " '左书右息': 1,\n",
       " '左首': 1,\n",
       " '左手指': 1,\n",
       " '左手腕': 1,\n",
       " '左手画方': 1,\n",
       " '左手': 1,\n",
       " '左上角': 1,\n",
       " '左上方': 1,\n",
       " '左上臂': 1,\n",
       " '左上': 1,\n",
       " '左嗓子': 1,\n",
       " '左炔诺孕酮': 1,\n",
       " '左券': 1,\n",
       " '左权县': 1,\n",
       " '左权墓': 1,\n",
       " '左权': 1,\n",
       " '左丘明': 1,\n",
       " '左晴雯': 1,\n",
       " '左倾机会主义': 1,\n",
       " '左倾': 1,\n",
       " '左强': 1,\n",
       " '左前卫': 1,\n",
       " '左铅右椠': 1,\n",
       " '左迁': 1,\n",
       " '左旗': 1,\n",
       " '左撇子': 1,\n",
       " '左膀右臂': 1,\n",
       " '左膀': 1,\n",
       " '左派': 1,\n",
       " '左木': 1,\n",
       " '左民党': 1,\n",
       " '左面': 1,\n",
       " '左绵': 1,\n",
       " '左满舵': 1,\n",
       " '左轮手枪': 1,\n",
       " '左轮': 1,\n",
       " '左路': 1,\n",
       " '左岭镇': 1,\n",
       " '左麟右李': 1,\n",
       " '左邻右舍': 1,\n",
       " '左邻右里': 1,\n",
       " '左列': 1,\n",
       " '左联五烈士': 1,\n",
       " '左联': 1,\n",
       " '左连璧': 1,\n",
       " '左拉': 1,\n",
       " '左近': 1,\n",
       " '左金丸': 1,\n",
       " '左脚': 1,\n",
       " '左江日报': 1,\n",
       " '左江': 1,\n",
       " '左键': 1,\n",
       " '左家庄': 1,\n",
       " '左家塘': 1,\n",
       " '左家': 1,\n",
       " '左焕琮': 1,\n",
       " '左焕琛': 1,\n",
       " '左后卫': 1,\n",
       " '左行': 1,\n",
       " '左海': 1,\n",
       " '左归丸': 1,\n",
       " '左顾右盼': 1,\n",
       " '左顾右眄': 1,\n",
       " '左贡县': 1,\n",
       " '左贡': 1,\n",
       " '左公柳': 1,\n",
       " '左各庄镇': 1,\n",
       " '左辅右弼': 1,\n",
       " '左锋': 1,\n",
       " '左方': 1,\n",
       " '左耳': 1,\n",
       " '左躲右闪': 1,\n",
       " '左端': 1,\n",
       " '左道旁门': 1,\n",
       " '左传': 1,\n",
       " '左丞相': 1,\n",
       " '左侧': 1,\n",
       " '左不过': 1,\n",
       " '左边前卫': 1,\n",
       " '左边锋': 1,\n",
       " '左边': 1,\n",
       " '左臂右膀': 1,\n",
       " '左臂': 1,\n",
       " '左岸': 1,\n",
       " '左安门': 1,\n",
       " '左安龙': 1,\n",
       " '左安安': 1,\n",
       " '左': 1,\n",
       " '阝': 1,\n",
       " '昨夜': 1,\n",
       " '昨晚': 1,\n",
       " '昨天': 1,\n",
       " '昨日': 1,\n",
       " '昨儿个': 1,\n",
       " '昨儿': 1,\n",
       " '昨': 1,\n",
       " '嘬嘬': 1,\n",
       " '嘬': 1,\n",
       " '撙撙': 1,\n",
       " '撙节': 1,\n",
       " '撙': 1,\n",
       " '鳟鱼': 1,\n",
       " '鳟': 1,\n",
       " '樽俎折冲': 1,\n",
       " '樽俎': 1,\n",
       " '樽前月下': 1,\n",
       " '樽': 1,\n",
       " '遵嘱': 1,\n",
       " '遵照': 1,\n",
       " '遵章守纪': 1,\n",
       " '遵章率': 1,\n",
       " '遵义县': 1,\n",
       " '遵义钛厂': 1,\n",
       " '遵义市政府': 1,\n",
       " '遵义市委': 1,\n",
       " '遵义市': 1,\n",
       " '遵义会议': 1,\n",
       " '遵义供电局': 1,\n",
       " '遵义': 1,\n",
       " '遵业': 1,\n",
       " '遵尧': 1,\n",
       " '遵养时晦': 1,\n",
       " '遵养晦时': 1,\n",
       " '遵养待时': 1,\n",
       " '遵厌兆祥': 1,\n",
       " '遵循': 1,\n",
       " '遵学': 1,\n",
       " '遵序': 1,\n",
       " '遵信': 1,\n",
       " '遵帅': 1,\n",
       " '遵守宪法': 1,\n",
       " '遵守': 1,\n",
       " '遵时养晦': 1,\n",
       " '遵生': 1,\n",
       " '遵钦': 1,\n",
       " '遵命': 1,\n",
       " '遵理': 1,\n",
       " '遵礼': 1,\n",
       " '遵敬': 1,\n",
       " '遵纪守法户': 1,\n",
       " '遵纪守法': 1,\n",
       " '遵纪爱民': 1,\n",
       " '遵纪': 1,\n",
       " '遵化县': 1,\n",
       " '遵化市': 1,\n",
       " '遵化': 1,\n",
       " '遵鸿': 1,\n",
       " '遵行': 1,\n",
       " '遵海': 1,\n",
       " '遵复': 1,\n",
       " '遵奉': 1,\n",
       " '遵法': 1,\n",
       " '遵而勿失': 1,\n",
       " '遵而不失': 1,\n",
       " '遵典': 1,\n",
       " '遵德': 1,\n",
       " '遵道秉义': 1,\n",
       " '遵道': 1,\n",
       " '遵从': 1,\n",
       " '遵': 1,\n",
       " '尊俎折冲': 1,\n",
       " '尊主泽民': 1,\n",
       " '尊主': 1,\n",
       " '尊重': 1,\n",
       " '尊者': 1,\n",
       " '尊长': 1,\n",
       " '尊章': 1,\n",
       " '尊造': 1,\n",
       " '尊远': 1,\n",
       " '尊仪': 1,\n",
       " '尊严感': 1,\n",
       " '尊严': 1,\n",
       " '尊萱': 1,\n",
       " '尊姓大名': 1,\n",
       " '尊姓': 1,\n",
       " '尊幸': 1,\n",
       " '尊贤使能': 1,\n",
       " '尊贤': 1,\n",
       " '尊无二上': 1,\n",
       " '尊翁': 1,\n",
       " '尊为': 1,\n",
       " '尊威': 1,\n",
       " '尊特拉': 1,\n",
       " '尊堂': 1,\n",
       " '尊肃': 1,\n",
       " '尊寿': 1,\n",
       " '尊师重教': 1,\n",
       " '尊师重道': 1,\n",
       " '尊师贵道': 1,\n",
       " '尊师': 1,\n",
       " '尊盛': 1,\n",
       " '尊胜陀罗尼经幢': 1,\n",
       " '尊胜': 1,\n",
       " '尊神': 1,\n",
       " '尊尚': 1,\n",
       " '尊容': 1,\n",
       " '尊荣': 1,\n",
       " '尊亲': 1,\n",
       " '尊年尚齿': 1,\n",
       " '尊明': 1,\n",
       " '尊礼': 1,\n",
       " '尊老敬老': 1,\n",
       " '尊老爱幼': 1,\n",
       " '尊老': 1,\n",
       " '尊君': 1,\n",
       " '尊爵': 1,\n",
       " '尊敬': 1,\n",
       " '尊介': 1,\n",
       " '尊驾': 1,\n",
       " '尊纪': 1,\n",
       " '尊华': 1,\n",
       " '尊厚': 1,\n",
       " '尊号': 1,\n",
       " '尊行': 1,\n",
       " '尊贵': 1,\n",
       " '尊古卑今': 1,\n",
       " '尊公': 1,\n",
       " '尊庚': 1,\n",
       " '尊刚': 1,\n",
       " '尊府': 1,\n",
       " '尊甫': 1,\n",
       " '尊夫人': 1,\n",
       " '尊奉': 1,\n",
       " '尊范': 1,\n",
       " '尊慈': 1,\n",
       " '尊宠': 1,\n",
       " '尊崇': 1,\n",
       " '尊驰': 1,\n",
       " '尊称': 1,\n",
       " '尊卑': 1,\n",
       " '尊宝': 1,\n",
       " '尊安': 1,\n",
       " '尊': 1,\n",
       " '醉枣': 1,\n",
       " '醉玉颓山': 1,\n",
       " '醉鱼草': 1,\n",
       " '醉意': 1,\n",
       " '醉眼': 1,\n",
       " '醉醺醺': 1,\n",
       " '醉心': 1,\n",
       " '醉乡': 1,\n",
       " '醉舞狂歌': 1,\n",
       " '醉舞': 1,\n",
       " '醉翁之意不在酒': 1,\n",
       " '醉翁亭记': 1,\n",
       " '醉翁亭': 1,\n",
       " '醉吐相茵': 1,\n",
       " '醉态': 1,\n",
       " '醉死梦生': 1,\n",
       " '醉生梦死': 1,\n",
       " '醉山颓倒': 1,\n",
       " '醉人': 1,\n",
       " '醉拳': 1,\n",
       " '醉梦花': 1,\n",
       " '醉马草': 1,\n",
       " '醉酒者': 1,\n",
       " '醉酒饱德': 1,\n",
       " '醉酒': 1,\n",
       " '醉鸡': 1,\n",
       " '醉话': 1,\n",
       " '醉汉': 1,\n",
       " '醉鬼': 1,\n",
       " '醉白池': 1,\n",
       " '醉': 1,\n",
       " '蕞': 1,\n",
       " '罪状': 1,\n",
       " '罪证': 1,\n",
       " '罪责难逃': 1,\n",
       " '罪责': 1,\n",
       " '罪有攸归': 1,\n",
       " '罪有应得': 1,\n",
       " '罪应万死': 1,\n",
       " '罪业深重': 1,\n",
       " '罪业': 1,\n",
       " '罪人不孥': 1,\n",
       " '罪人': 1,\n",
       " '罪愆': 1,\n",
       " '罪孽深重': 1,\n",
       " '罪孽': 1,\n",
       " '罪逆深重': 1,\n",
       " '罪名': 1,\n",
       " '罪魁祸首': 1,\n",
       " '罪魁': 1,\n",
       " '罪加一等': 1,\n",
       " '罪行': 1,\n",
       " '罪过形式': 1,\n",
       " '罪过': 1,\n",
       " '罪该万死': 1,\n",
       " '罪犯': 1,\n",
       " '罪恶滔天': 1,\n",
       " '罪恶贯盈': 1,\n",
       " '罪恶感': 1,\n",
       " '罪恶都市': 1,\n",
       " '罪恶的黑手': 1,\n",
       " '罪恶': 1,\n",
       " '罪当万死': 1,\n",
       " '罪大恶极': 1,\n",
       " '罪错': 1,\n",
       " '罪不胜诛': 1,\n",
       " '罪不容诛': 1,\n",
       " '罪不容赦': 1,\n",
       " '罪不可逭': 1,\n",
       " '罪案率': 1,\n",
       " '罪案': 1,\n",
       " '罪': 1,\n",
       " '最最': 1,\n",
       " '最重': 1,\n",
       " '最终幻想': 1,\n",
       " '最终': 1,\n",
       " '最长': 1,\n",
       " '最早': 1,\n",
       " '最远点': 1,\n",
       " '最远': 1,\n",
       " '最游记': 1,\n",
       " '最优化': 1,\n",
       " '最新作品': 1,\n",
       " '最新咨讯': 1,\n",
       " '最新专辑': 1,\n",
       " '最新政策': 1,\n",
       " '最新招聘': 1,\n",
       " '最新战况': 1,\n",
       " '最新在线': 1,\n",
       " '最新音乐': 1,\n",
       " '最新讯息': 1,\n",
       " '最新型': 1,\n",
       " '最新消息': 1,\n",
       " '最新下载': 1,\n",
       " '最新文章': 1,\n",
       " '最新图片': 1,\n",
       " '最新商情': 1,\n",
       " '最新软件': 1,\n",
       " '最新期刊': 1,\n",
       " '最新漏洞': 1,\n",
       " '最新楼盘': 1,\n",
       " '最新景点': 1,\n",
       " '最新技术': 1,\n",
       " '最新活动': 1,\n",
       " '最新公告': 1,\n",
       " '最新更新': 1,\n",
       " '最新法规': 1,\n",
       " '最新发行': 1,\n",
       " '最新电影': 1,\n",
       " '最新大片': 1,\n",
       " '最新产品': 1,\n",
       " '最新报价': 1,\n",
       " '最新报道': 1,\n",
       " '最新版': 1,\n",
       " '最新': 1,\n",
       " '最小化': 1,\n",
       " '最小公倍数': 1,\n",
       " '最小': 1,\n",
       " '最先': 1,\n",
       " '最为': 1,\n",
       " '最深': 1,\n",
       " '最少': 1,\n",
       " '最全面': 1,\n",
       " '最全': 1,\n",
       " '最轻量级': 1,\n",
       " '最强音': 1,\n",
       " '最强': 1,\n",
       " '最前沿': 1,\n",
       " '最起码': 1,\n",
       " '最末': 1,\n",
       " '最美': 1,\n",
       " '最快': 1,\n",
       " '最近新书': 1,\n",
       " '最近似值': 1,\n",
       " '最近': 1,\n",
       " '最简式': 1,\n",
       " '最简论坛': 1,\n",
       " '最简分数': 1,\n",
       " '最佳期': 1,\n",
       " '最佳奖': 1,\n",
       " '最佳化': 1,\n",
       " '最佳': 1,\n",
       " '最惠国待遇': 1,\n",
       " '最惠国': 1,\n",
       " '最惠': 1,\n",
       " '最後': 1,\n",
       " '最后战士': 1,\n",
       " '最后一秒': 1,\n",
       " '最后通牒': 1,\n",
       " '最后通谍': 1,\n",
       " '最后的晚餐': 1,\n",
       " '最后的审判': 1,\n",
       " '最后的爱': 1,\n",
       " '最后': 1,\n",
       " '最好': 1,\n",
       " '最高值': 1,\n",
       " '最高者': 1,\n",
       " '最高院': 1,\n",
       " '最高人民检察院政治部': 1,\n",
       " '最高人民检察院': 1,\n",
       " '最高人民法院审判委员会': 1,\n",
       " '最高人民法院党组': 1,\n",
       " '最高人民法院': 1,\n",
       " '最高检察院': 1,\n",
       " '最高检': 1,\n",
       " '最高价': 1,\n",
       " '最高级': 1,\n",
       " '最高峰': 1,\n",
       " '最高分': 1,\n",
       " '最高法院': 1,\n",
       " '最高额': 1,\n",
       " '最高点': 1,\n",
       " '最高处': 1,\n",
       " '最高潮': 1,\n",
       " '最高层': 1,\n",
       " '最高': 1,\n",
       " '最底层': 1,\n",
       " '最低值': 1,\n",
       " '最低限': 1,\n",
       " '最低价': 1,\n",
       " '最低谷': 1,\n",
       " '最低点': 1,\n",
       " '最低': 1,\n",
       " '最大值': 1,\n",
       " '最大者': 1,\n",
       " '最大化': 1,\n",
       " '最大公约数': 1,\n",
       " '最大': 1,\n",
       " '最初的爱': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/zh_words.csv', encoding='gbk')\n",
    "words = data.iloc[:,0]\n",
    "w = zip(words, [1 for _ in range(len(words))])\n",
    "w = dict(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T04:59:26.772896Z",
     "start_time": "2020-02-26T04:59:26.741888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 1]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx = [1, 2, 4]\n",
    "xxx = xxx[::-1]\n",
    "xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 搭建一个分词工具\n",
    "\n",
    "### Part 1.1  基于枚举方法来搭建中文分词工具\n",
    "\n",
    "此项目需要的数据：\n",
    "1. 综合类中文词库.xlsx： 包含了中文词，当做词典来用\n",
    "2. 以变量的方式提供了部分unigram概率 word_prob\n",
    "\n",
    "\n",
    "举个例子： 给定词典=[我们 学习 人工 智能 人工智能 未来 是]， 另外我们给定unigram概率：p(我们)=0.25, p(学习)=0.15, p(人工)=0.05, p(智能)=0.1, p(人工智能)=0.2, p(未来)=0.1, p(是)=0.15\n",
    "\n",
    "#### Step 1: 对于给定字符串：”我们学习人工智能，人工智能是未来“, 找出所有可能的分割方式\n",
    "- [我们，学习，人工智能，人工智能，是，未来]\n",
    "- [我们，学习，人工，智能，人工智能，是，未来]\n",
    "- [我们，学习，人工，智能，人工，智能，是，未来]\n",
    "- [我们，学习，人工智能，人工，智能，是，未来]\n",
    ".......\n",
    "\n",
    "\n",
    "#### Step 2: 我们也可以计算出每一个切分之后句子的概率\n",
    "- p(我们，学习，人工智能，人工智能，是，未来)= -log p(我们)-log p(学习)-log p(人工智能)-log p(人工智能)-log p(是)-log p(未来)\n",
    "- p(我们，学习，人工，智能，人工智能，是，未来)=-log p(我们)-log p(学习)-log p(人工)-log p(智能)-log p(人工智能)-log p(是)-log p(未来)\n",
    "- p(我们，学习，人工，智能，人工，智能，是，未来)=-log p(我们)-log p(学习)-log p(人工)-log p(智能)-log p(人工)-log p(智能)-log p(是)-log p(未来)\n",
    "- p(我们，学习，人工智能，人工，智能，是，未来)=-log p(我们)-log p(学习)-log p(人工智能)-log p(人工)-log p(智能)-log(是)-log p(未来)\n",
    ".....\n",
    "\n",
    "#### Step 3: 返回第二步中概率最大的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T12:15:09.841462Z",
     "start_time": "2020-02-24T12:15:09.817447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# TODO: 第一步： 从dic.txt中读取所有中文词。\n",
    "#  hint: 思考一下用什么数据结构来存储这个词典会比较好？ 要考虑我们每次查询一个单词的效率。 \n",
    "dic_words =  w   # 保存词典库中读取的单词\n",
    "\n",
    "# 以下是每一个单词出现的概率。为了问题的简化，我们只列出了一小部分单词的概率。 在这里没有出现的的单词但是出现在词典里的，统一把概率设置成为0.00001\n",
    "# 比如 p(\"学院\")=p(\"概率\")=...0.00001\n",
    "\n",
    "word_prob = {\"北京\":0.03,\"的\":0.08,\"天\":0.005,\"气\":0.005,\"天气\":0.06,\"真\":0.04,\"好\":0.05,\"真好\":0.04,\"啊\":0.01,\"真好啊\":0.02, \n",
    "             \"今\":0.01,\"今天\":0.07,\"课程\":0.06,\"内容\":0.06,\"有\":0.05,\"很\":0.03,\"很有\":0.04,\"意思\":0.06,\"有意思\":0.005,\"课\":0.01,\n",
    "             \"程\":0.005,\"经常\":0.08,\"意见\":0.08,\"意\":0.01,\"见\":0.005,\"有意见\":0.02,\"分歧\":0.04,\"分\":0.02, \"歧\":0.005}\n",
    "\n",
    "print (sum(word_prob.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T12:31:28.529332Z",
     "start_time": "2020-02-24T12:31:28.208390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京', '的', '天气', '真好', '啊']\n"
     ]
    }
   ],
   "source": [
    "#  分数（10）\n",
    "## TODO 请编写word_segment_naive函数来实现对输入字符串的分词\n",
    "def word_segment_naive(input_str):\n",
    "    \"\"\"\n",
    "    1. 对于输入字符串做分词，并返回所有可行的分词之后的结果。\n",
    "    2. 针对于每一个返回结果，计算句子的概率\n",
    "    3. 返回概率最高的最作为最后结果\n",
    "    \n",
    "    input_str: 输入字符串   输入格式：“今天天气好”\n",
    "    best_segment: 最好的分词结果  输出格式：[\"今天\"，\"天气\"，\"好\"]\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO： 第一步： 计算所有可能的分词结果，要保证每个分完的词存在于词典里，这个结果有可能会非常多。 \n",
    "    segments = []  # 存储所有分词的结果。如果次字符串不可能被完全切分，则返回空列表(list)\n",
    "                   # 格式为：segments = [[\"今天\"，“天气”，“好”],[\"今天\"，“天“，”气”，“好”],[\"今“，”天\"，“天气”，“好”],...]\n",
    "    temp = []\n",
    "    # 长度为l的字符串共有l-1个空隙可以插入\n",
    "    n = len(input_str) - 1\n",
    "    for i in range(1<<n):\n",
    "        temp = []\n",
    "        for j in range(n):\n",
    "            temp.append(1&(i>>j))\n",
    "        seg = []\n",
    "        indices = []\n",
    "        for k in range(len(temp)):\n",
    "            if temp[k] == 1:\n",
    "                indices.append(k)\n",
    "#       print(indices)\n",
    "#       我肯定是写复杂了\n",
    "        if len(indices) == 0:\n",
    "            seg.append(input_str)\n",
    "        elif len(indices) == 1:\n",
    "            seg.append(input_str[0:indices[0]+1])\n",
    "            seg.append(input_str[indices[0]+1:])\n",
    "        elif len(indices) == 2:\n",
    "            seg.append(input_str[0:indices[0]+1])\n",
    "            seg.append(input_str[indices[0]+1:indices[1]+1])\n",
    "            seg.append(input_str[indices[1]+1:])\n",
    "        else:\n",
    "            for k in range(len(indices)):\n",
    "                if k == 0:\n",
    "                    seg.append(input_str[0:indices[k]+1])\n",
    "                if k == len(indices)-1:\n",
    "                    seg.append(input_str[indices[k]+1:])\n",
    "                else:\n",
    "                    seg.append(input_str[indices[k]+1:indices[k+1]+1])\n",
    "#       print(seg)\n",
    "        flag = 0\n",
    "        for k in seg:\n",
    "            if w.get(k) is None:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            segments.append(seg)\n",
    "            \n",
    "            \n",
    "    # TODO: 第二步：循环所有的分词结果，并计算出概率最高的分词结果，并返回\n",
    "    best_segment = segments[0]\n",
    "    best_score = 10000\n",
    "    for seg in segments:\n",
    "        score = 1\n",
    "#       print(seg)\n",
    "        for word in seg:\n",
    "            if word_prob.get(word) is None:\n",
    "                ratio = -math.log(0.00001)\n",
    "            else:\n",
    "                ratio = -math.log(word_prob.get(word))\n",
    "            score = score * ratio\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_segment = seg\n",
    "    return best_segment   \n",
    "\n",
    "print (word_segment_naive(\"北京的天气真好啊\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T03:35:58.707144Z",
     "start_time": "2020-02-26T03:35:58.661103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京', '的', '天气', '真好', '啊']\n",
      "['今天', '的', '课程', '内容', '很', '有意思']\n",
      "['经常', '有', '意见', '分歧']\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "print(word_segment_naive(\"北京的天气真好啊\"))\n",
    "print(word_segment_naive(\"今天的课程内容很有意思\"))\n",
    "print(word_segment_naive(\"经常有意见分歧\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2  基于维特比算法来优化上述流程\n",
    "\n",
    "此项目需要的数据：\n",
    "1. 综合类中文词库.xlsx： 包含了中文词，当做词典来用\n",
    "2. 以变量的方式提供了部分unigram概率word_prob\n",
    "\n",
    "\n",
    "举个例子： 给定词典=[我们 学习 人工 智能 人工智能 未来 是]， 另外我们给定unigram概率：p(我们)=0.25, p(学习)=0.15, p(人工)=0.05, p(智能)=0.1, p(人工智能)=0.2, p(未来)=0.1, p(是)=0.15\n",
    "\n",
    "#### Step 1: 根据词典，输入的句子和 word_prob来创建带权重的有向图（Directed Graph） 参考：课程内容\n",
    "有向图的每一条边是一个单词的概率（只要存在于词典里的都可以作为一个合法的单词），这些概率已经给出（存放在word_prob）。\n",
    "注意：思考用什么方式来存储这种有向图比较合适？ 不一定只有一种方式来存储这种结构。 \n",
    "\n",
    "#### Step 2: 编写维特比算法（viterebi）算法来找出其中最好的PATH， 也就是最好的句子切分\n",
    "具体算法参考课程中讲过的内容\n",
    "\n",
    "#### Step 3: 返回结果\n",
    "跟PART 1.1的要求一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T05:09:34.640362Z",
     "start_time": "2020-02-26T05:09:34.304768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京', '的', '天气', '真好啊']\n"
     ]
    }
   ],
   "source": [
    "# 分数（10）\n",
    "import numpy as np\n",
    "\n",
    "## TODO 请编写word_segment_viterbi函数来实现对输入字符串的分词\n",
    "def word_segment_viterbi(input_str):\n",
    "    \"\"\"\n",
    "    1. 基于输入字符串，词典，以及给定的unigram概率来创建DAG(有向图）。\n",
    "    2. 编写维特比算法来寻找最优的PATH\n",
    "    3. 返回分词结果\n",
    "    \n",
    "    input_str: 输入字符串   输入格式：“今天天气好”\n",
    "    best_segment: 最好的分词结果  输出格式：[\"今天\"，\"天气\"，\"好\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: 第一步：根据词典，输入的句子，以及给定的unigram概率来创建带权重的有向图（Directed Graph） 参考：课程内容\n",
    "    #      有向图的每一条边是一个单词的概率（只要存在于词典里的都可以作为一个合法的单词），这些概率在 word_prob，如果不在word_prob里的单词但在\n",
    "    #      词典里存在的，统一用概率值0.00001。\n",
    "    #      注意：思考用什么方式来存储这种有向图比较合适？ 不一定有只有一种方式来存储这种结构。\n",
    "    node_num = len(input_str) + 1\n",
    "    graph = np.zeros((node_num, node_num), dtype=int)\n",
    "    for i in range(node_num):\n",
    "        for j in range(i, node_num):\n",
    "            if i != j:\n",
    "                if word_prob.get(input_str[i:j]) is None:\n",
    "                    if j-i == 1:\n",
    "                        ratio = -math.log(0.00001)\n",
    "                    else:\n",
    "                        ratio = 0\n",
    "                else:\n",
    "                    ratio = -math.log(word_prob.get(input_str[i:j]))\n",
    "                graph[i][j] = ratio\n",
    "    \n",
    "    # TODO： 第二步： 利用维特比算法来找出最好的PATH， 这个PATH是P(sentence)最大或者 -log P(sentence)最小的PATH。\n",
    "    #              hint: 思考为什么不用相乘: p(w1)p(w2)...而是使用negative log sum:  -log(w1)-log(w2)-...\n",
    "    dp = [10000 for _ in range(node_num)]\n",
    "    dp[0] = 0\n",
    "    path = [0 for _ in range(node_num)]\n",
    "    for i in range(1, node_num):\n",
    "        for j in range(i):\n",
    "            # 如果有这样的一条边\n",
    "            if graph[j][i] != 0:\n",
    "                if dp[j] + graph[j][i] < dp[i]:\n",
    "                    # 更新并记录路径\n",
    "                    dp[i] = dp[j] + graph[j][i]\n",
    "                    path[i] = j\n",
    "    index = []\n",
    "    last = len(path)-1\n",
    "    while last != 0:\n",
    "        index.append(path[last])\n",
    "        last = path[last]\n",
    "    \n",
    "    # TODO: 第三步： 根据最好的PATH, 返回最好的切分\n",
    "    index = index[::-1]\n",
    "    best_segment = []\n",
    "    for i in range(len(index)):\n",
    "        if i == len(index) -1:\n",
    "            best_segment.append(input_str[index[i]:])\n",
    "        else:\n",
    "            best_segment.append(input_str[index[i]:index[i+1]])\n",
    "    return best_segment     \n",
    "\n",
    "print (word_segment_viterbi(\"北京的天气真好啊\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T05:10:37.437346Z",
     "start_time": "2020-02-26T05:10:37.398338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['北京', '的', '天气', '真好啊']\n",
      "['今天', '的', '课程', '内容', '很有', '意思']\n",
      "['经常', '有意见', '分歧']\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "print(word_segment_viterbi(\"北京的天气真好啊\"))\n",
    "print(word_segment_viterbi(\"今天的课程内容很有意思\"))\n",
    "print(word_segment_viterbi(\"经常有意见分歧\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分数（3）\n",
    "# TODO: 第一种方法和第二种方法的时间复杂度和空间复杂度分别是多少？\n",
    "第一个方法： \n",
    "时间复杂度= , 空间复杂度=\n",
    "\n",
    "第二个方法：\n",
    "时间复杂度= , 空间复杂度="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分数（2）\n",
    "# TODO：如果把上述的分词工具持续优化，有哪些可以考虑的方法？ （至少列出3点）\n",
    "- 0. （例）， 目前的概率是不完整的，可以考虑大量的语料库，然后从中计算出每一个词出现的概率，这样更加真实\n",
    "- 1.\n",
    "- 2.\n",
    "- 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2:  搭建一个简单的问答系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次项目的目标是搭建一个基于检索式的简单的问答系统。至于什么是检索式的问答系统请参考课程直播内容/PPT介绍。 \n",
    "\n",
    "通过此项目，你将会有机会掌握以下几个知识点：\n",
    "1. 字符串操作   2. 文本预处理技术（词过滤，标准化）   3. 文本的表示（tf-idf, word2vec)  4. 文本相似度计算  5. 文本高效检索\n",
    "\n",
    "此项目需要的数据：\n",
    "1. dev-v2.0.json: 这个数据包含了问题和答案的pair， 但是以JSON格式存在，需要编写parser来提取出里面的问题和答案。 \n",
    "2. glove.6B: 这个文件需要从网上下载，下载地址为：https://nlp.stanford.edu/projects/glove/， 请使用d=100的词向量\n",
    "\n",
    "##### 检索式的问答系统\n",
    "问答系统所需要的数据已经提供，对于每一个问题都可以找得到相应的答案，所以可以理解为每一个样本数据是 <问题、答案>。 那系统的核心是当用户输入一个问题的时候，首先要找到跟这个问题最相近的已经存储在库里的问题，然后直接返回相应的答案即可。 举一个简单的例子：\n",
    "\n",
    "假设我们的库里面已有存在以下几个<问题,答案>：\n",
    "<\"贪心学院主要做什么方面的业务？”， “他们主要做人工智能方面的教育”>\n",
    "<“国内有哪些做人工智能教育的公司？”， “贪心学院”>\n",
    "<\"人工智能和机器学习的关系什么？\", \"其实机器学习是人工智能的一个范畴，很多人工智能的应用要基于机器学习的技术\">\n",
    "<\"人工智能最核心的语言是什么？\"， ”Python“>\n",
    ".....\n",
    "\n",
    "假设一个用户往系统中输入了问题 “贪心学院是做什么的？”， 那这时候系统先去匹配最相近的“已经存在库里的”问题。 那在这里很显然是 “贪心学院是做什么的”和“贪心学院主要做什么方面的业务？”是最相近的。 所以当我们定位到这个问题之后，直接返回它的答案 “他们主要做人工智能方面的教育”就可以了。 所以这里的核心问题可以归结为计算两个问句（query）之间的相似度。\n",
    "\n",
    "在本次项目中，你会频繁地使用到sklearn这个机器学习库。具体安装请见：http://scikit-learn.org/stable/install.html  sklearn包含了各类机器学习算法和数据处理工具，包括本项目需要使用的词袋模型，均可以在sklearn工具包中找得到。 另外，本项目还需要用到分词工具jieba, 具体使用方法请见 https://github.com/fxsjy/jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1  第一部分： 读取文件，并把内容分别写到两个list里（一个list对应问题集，另一个list对应答案集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T13:37:44.998692Z",
     "start_time": "2020-02-24T13:37:42.921157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86821"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分数（5）\n",
    "import json\n",
    "def read_corpus():\n",
    "    \"\"\"\n",
    "    读取给定的语料库，并把问题列表和答案列表分别写入到 qlist, alist 里面。 在此过程中，不用对字符换做任何的处理（这部分需要在 Part 2.3里处理）\n",
    "    qlist = [\"问题1\"， “问题2”， “问题3” ....]\n",
    "    alist = [\"答案1\", \"答案2\", \"答案3\" ....]\n",
    "    务必要让每一个问题和答案对应起来（下标位置一致）\n",
    "    \"\"\"\n",
    "    qlist = []\n",
    "    alist = []\n",
    "    with open('./data/train-v2.0.json') as f:\n",
    "        qa = json.load(f)\n",
    "    data = qa.get('data')\n",
    "    data_num = len(data)\n",
    "    print(data_num)\n",
    "    for k in range(data_num):\n",
    "        paragraphs = data[k].get('paragraphs')\n",
    "        paragraphs_num = len(paragraphs)\n",
    "        # print(paragraphs_num)\n",
    "        for i in range(paragraphs_num):\n",
    "            qas = paragraphs[i].get('qas')\n",
    "            qas_num = len(qas)\n",
    "            for j in range(qas_num):\n",
    "                try:\n",
    "                    question = qas[j].get('question')\n",
    "                    answer = qas[j].get('answers')[0].get('text')\n",
    "                    # print(question)\n",
    "                    # print(answer)\n",
    "                    qlist.append(question)\n",
    "                    alist.append(answer)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "    assert len(qlist) == len(alist)  # 确保长度一样\n",
    "    return qlist, alist\n",
    "\n",
    "ql, al = read_corpus()\n",
    "len(ql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 理解数据（可视化分析/统计信息）\n",
    "对数据的理解是任何AI工作的第一步，需要充分对手上的数据有个更直观的理解。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T02:07:38.484829Z",
     "start_time": "2020-02-26T02:07:38.430851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the name of the student newspaper?',\n",
       " 'What is the name of the lifestyle magazine?',\n",
       " 'What is another magazine that is published in Oklahoma City?',\n",
       " 'What was the third Radio Station in the US?',\n",
       " 'When was WKY granted a federal license?',\n",
       " \"When did E.K. Gaylord's Oklahoma Publishing Compan buy WKY Radio?\",\n",
       " 'What is the current station called?',\n",
       " 'What rank is Oklahoma Cities television networks for Nielsen?',\n",
       " 'How many counties does Oklahoma Cities Networks cover?',\n",
       " 'How many  people are paid to be employed by the Oklahoma City Fire department?']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分数（10）\n",
    "# TODO: 统计一下在qlist 总共出现了多少个单词？ 总共出现了多少个不同的单词？\n",
    "#       这里需要做简单的分词，对于英文我们根据空格来分词即可，其他过滤暂不考虑（只需分词）\n",
    "ql[10000:10010]\n",
    "\n",
    "# print (word_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: 统计一下qlist中每个单词出现的频率，并把这些频率排一下序，然后画成plot. 比如总共出现了总共7个不同单词，而且每个单词出现的频率为 4, 5,10,2, 1, 1,1\n",
    "#       把频率排序之后就可以得到(从大到小) 10, 5, 4, 2, 1, 1, 1. 然后把这7个数plot即可（从大到小）\n",
    "#       需要使用matplotlib里的plot函数。y轴是词频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO： 从上面的图中能观察到什么样的现象？ 这样的一个图的形状跟一个非常著名的函数形状很类似，能所出此定理吗？ \n",
    "#       hint: [XXX]'s law\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: 在qlist和alist里出现次数最多的TOP 10单词分别是什么？ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 文本预处理\n",
    "次部分需要尝试做文本的处理。在这里我们面对的是英文文本，所以任何对英文适合的技术都可以考虑进来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分数（10）\n",
    "\n",
    "# TODO: 对于qlist, alist做文本预处理操作。 可以考虑以下几种操作：\n",
    "#       1. 停用词过滤 （去网上搜一下 \"english stop words list\"，会出现很多包含停用词库的网页，或者直接使用NLTK自带的）   \n",
    "#       2. 转换成lower_case： 这是一个基本的操作   \n",
    "#       3. 去掉一些无用的符号： 比如连续的感叹号！！！， 或者一些奇怪的单词。\n",
    "#       4. 去掉出现频率很低的词：比如出现次数少于10,20....\n",
    "#       5. 对于数字的处理： 分词完只有有些单词可能就是数字比如44，415，把所有这些数字都看成是一个单词，这个新的单词我们可以定义为 \"#number\"\n",
    "#       6. stemming（利用porter stemming): 因为是英文，所以stemming也是可以做的工作\n",
    "#       7. 其他（如果有的话）\n",
    "#       请注意，不一定要按照上面的顺序来处理，具体处理的顺序思考一下，然后选择一个合理的顺序\n",
    "#  hint: 停用词用什么数据结构来存储？ 不一样的数据结构会带来完全不一样的效率！ \n",
    "\n",
    "qlist, alist =    # 更新后的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: 在前面步骤里，我们删除了出现次数比较少的单词，那你选择的阈值是多少（小于多少的去掉？）， 这个阈值是根据什么来选择的？ \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 文本表示\n",
    "当我们做完关键的预处理过程之后，就需要把每一个文本转换成向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分数（10）\n",
    "\n",
    "# TODO: 把qlist中的每一个问题字符串转换成tf-idf向量, 转换之后的结果存储在X矩阵里。 X的大小是： N* D的矩阵。 这里N是问题的个数（样本个数），\n",
    "#       D是字典库的大小。 \n",
    "\n",
    "vectorizer =  # 定义一个tf-idf的vectorizer\n",
    "\n",
    "X =   # 结果存放在X矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: 矩阵X有什么特点？ 计算一下它的稀疏度\n",
    "\n",
    "print (sparsity)  # 打印出稀疏度(sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 对于用户的输入问题，找到相似度最高的TOP5问题，并把5个潜在的答案做返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分数（10）\n",
    "\n",
    "def top5results(input_q):\n",
    "    \"\"\"\n",
    "    给定用户输入的问题 input_q, 返回最有可能的TOP 5问题。这里面需要做到以下几点：\n",
    "    1. 对于用户的输入 input_q 首先做一系列的预处理，然后再转换成tf-idf向量（利用上面的vectorizer)\n",
    "    2. 计算跟每个库里的问题之间的相似度\n",
    "    3. 找出相似度最高的top5问题的答案\n",
    "    \"\"\"\n",
    "    \n",
    "    top_idxs = []  # top_idxs存放相似度最高的（存在qlist里的）问题的下表 \n",
    "                   # hint: 利用priority queue来找出top results. 思考为什么可以这么做？ \n",
    "    \n",
    "    return alist[top_idxs]  # 返回相似度最高的问题对应的答案，作为TOP5答案    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: 编写几个测试用例，并输出结果\n",
    "print (top5results(\"\"))\n",
    "print (top5results(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分数（5）\n",
    "\n",
    "# TODO: 上面的top5results算法的时间复杂度和空间复杂度分别是多少？\n",
    "\n",
    "时间复杂度 = O()， 空间复杂度 = O()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 利用倒排表的优化。 \n",
    "上面的算法，一个最大的缺点是每一个用户问题都需要跟库里的所有的问题都计算相似度。假设我们库里的问题非常多，这将是效率非常低的方法。 这里面一个方案是通过倒排表的方式，先从库里面找到跟当前的输入类似的问题描述。然后针对于这些candidates问题再做余弦相似度的计算。这样会节省大量的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分数（10）\n",
    "\n",
    "# TODO: 基于倒排表的优化。在这里，我们可以定义一个类似于hash_map, 比如 inverted_index = {}， 然后存放包含每一个关键词的文档出现在了什么位置，\n",
    "#       也就是，通过关键词的搜索首先来判断包含这些关键词的文档（比如出现至少一个），然后对于candidates问题做相似度比较。\n",
    "# \n",
    "inverted_idx = {}  # 定一个一个简单的倒排表\n",
    "def top5results_invidx(input_q):\n",
    "    \"\"\"\n",
    "    给定用户输入的问题 input_q, 返回最有可能的TOP 5问题。这里面需要做到以下几点：\n",
    "    1. 利用倒排表来筛选 candidate\n",
    "    2. 对于用户的输入 input_q 首先做一系列的预处理，然后再转换成tf-idf向量（利用上面的vectorizer)\n",
    "    3. 计算跟每个库里的问题之间的相似度\n",
    "    4. 找出相似度最高的top5问题的答案\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: 编写几个测试用例，并输出结果\n",
    "print (top5results_invidx(\"\"))\n",
    "print (top5results_invidx(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分数（3）\n",
    "\n",
    "# TODO: 上面的top5results算法的时间复杂度和空间复杂度分别是多少？\n",
    "\n",
    "时间复杂度 = O()， 空间复杂度 = O()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 基于词向量的文本表示\n",
    "上面所用到的方法论是基于词袋模型（bag-of-words model）。这样的方法论有两个主要的问题：1. 无法计算词语之间的相似度  2. 稀疏度很高。 在2.7里面我们\n",
    "讲采用词向量作为文本的表示。词向量方面需要下载： https://nlp.stanford.edu/projects/glove/ （请下载glove.6B.zip），并使用d=100的词向量（100维）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分数（10）\n",
    "\n",
    "# TODO\n",
    "emb = # 读取每一个单词的嵌入。这个是 D*H的矩阵，这里的D是词典库的大小， H是词向量的大小。 这里面我们给定的每个单词的词向量，那句子向量怎么表达？\n",
    "      # 其中，最简单的方式 句子向量 = 词向量的平均（出现在问句里的）， 如果给定的词没有出现在词典库里，则忽略掉这个词。\n",
    "\n",
    "def top5results_emb(input_q):\n",
    "    \"\"\"\n",
    "    给定用户输入的问题 input_q, 返回最有可能的TOP 5问题。这里面需要做到以下几点：\n",
    "    1. 利用倒排表来筛选 candidate\n",
    "    2. 对于用户的输入 input_q，转换成句子向量\n",
    "    3. 计算跟每个库里的问题之间的相似度\n",
    "    4. 找出相似度最高的top5问题的答案\n",
    "    \"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: 编写几个测试用例，并输出结果\n",
    "print (top5results_emb(\"\"))\n",
    "print (top5results_emb(\"\"))\n",
    "\n",
    "# 我们在验收作业时在后台会建立几个测试用例，来验证返回的准确性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.8 做完本次项目做完之后有什么收获？ \n",
    "\n",
    "#分数（2）\n",
    "\n",
    "回答 = “”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
